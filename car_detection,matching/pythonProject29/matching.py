import os
import csv
import numpy as np
from scipy.optimize import linear_sum_assignment
import subprocess
import sys
from collections import defaultdict

# -------------------- ê²½ë¡œ ì„¤ì • --------------------
detect_csv_folder = "detect_csv"
reid_feature_folder = "reid_features"
match_csv_folder = "matching_csv"
PAIR_CSV_PATH = "t0t1_two.csv"  # í˜ì–´ íŒŒì¼ ê²½ë¡œ
os.makedirs(match_csv_folder, exist_ok=True)

# -------------------- (íŠœë‹ ê°€ëŠ¥í•œ) ë§¤ì¹­ ì¡°ê±´ --------------------
IOU_THRESH = 0.03
CENTER_RATIO = 1.5
SIZE_SIM_THRESH = 0.35
REID_COSINE_THRESH = 0.20
MIN_BBOX_SIZE = 12
ALPHA = 0.2
BETA = 0.8
TOP_N_REID = 3
NEAREST_PIXELS = 200
FINAL_SCORE_THRESH = 0.18


# -------------------- ìœ í‹¸ í•¨ìˆ˜ --------------------

def compute_iou(box1, box2):
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])
    inter_area = max(0, x2 - x1) * max(0, y2 - y1)
    area1 = max(0, (box1[2] - box1[0])) * max(0, (box1[3] - box1[1]))
    area2 = max(0, (box2[2] - box2[0])) * max(0, (box2[3] - box2[1]))
    union_area = area1 + area2 - inter_area
    return inter_area / union_area if union_area > 0 else 0.0


def center_distance(box1, box2):
    cx1, cy1 = (box1[0] + box1[2]) / 2.0, (box1[1] + box1[3]) / 2.0
    cx2, cy2 = (box2[0] + box2[2]) / 2.0, (box2[1] + box2[3]) / 2.0
    return float(np.sqrt((cx1 - cx2) ** 2 + (cy1 - cy2) ** 2))


def size_similarity(box1, box2):
    w1, h1 = box1[2] - box1[0], box1[3] - box1[1]
    w2, h2 = box2[2] - box2[0], box2[3] - box2[1]
    area1, area2 = max(0, w1 * h1), max(0, w2 * h2)
    return (min(area1, area2) / max(area1, area2)) if max(area1, area2) > 0 else 0.0


def cosine_similarity(f1, f2):
    if f1 is None or f2 is None:
        return 0.0
    n1 = np.linalg.norm(f1)
    n2 = np.linalg.norm(f2)
    if n1 == 0 or n2 == 0:
        return 0.0
    return float(np.dot(f1, f2) / (n1 * n2))


def load_features(csv_file):
    base_name = os.path.splitext(csv_file)[0]
    if base_name.lower().endswith('_detect'):
        base_name = base_name[:-7]

    feature_path = os.path.join(reid_feature_folder, base_name + "_features.npy")

    if not os.path.exists(feature_path):
        return []
    return np.load(feature_path, allow_pickle=True)


def read_detect_csv(csv_file):
    bboxes = []
    file_path = os.path.join(detect_csv_folder, csv_file)

    if not os.path.exists(file_path):
        return bboxes

    try:
        with open(file_path, "r", newline='') as f:
            reader = csv.DictReader(f)
            for row in reader:
                try:
                    x1, y1, x2, y2 = int(float(row["x1"])), int(float(row["y1"])), int(float(row["x2"])), int(
                        float(row["y2"]))
                except:
                    continue
                bboxes.append([x1, y1, x2, y2])
    except Exception as e:
        print(f"[ì˜¤ë¥˜] CSV íŒŒì¼ ì½ê¸° ì¤‘ ë¬¸ì œ ë°œìƒ: {file_path} - {e}")
        return bboxes

    return bboxes


#  T0/T1 ì ‘ë¯¸ì‚¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ íŒŒì¼ëª…ì„ ìœ ì¶”í•˜ë„ë¡ ìˆ˜ì •
def complete_filename(base_name, detect_csv_folder, is_t0):
    """
    t0t1_augmented.csvì˜ ë¶ˆì™„ì „í•œ ì´ë¦„(0001_top)ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ detect_csv íŒŒì¼ì„ ì°¾ìŒ.
    is_t0=TrueëŠ” t0 íŒŒì¼ì„, FalseëŠ” t1 íŒŒì¼ì„ ì°¾ì•„ì•¼ í•¨ì„ ì˜ë¯¸.
    """

    # 1. ì´ë¯¸ ì™„ì„±ëœ ì´ë¦„ì´ë¼ë©´ ë°”ë¡œ ë°˜í™˜
    if base_name.lower().endswith('_detect.csv'):
        file_path = os.path.join(detect_csv_folder, base_name)
        if os.path.exists(file_path):
            return base_name

    # 2. base_nameì„ ì ‘ë‘ì‚¬ë¡œ ê°€ì§€ê³ , t0/t1 ì •ë³´ê°€ í¬í•¨ëœ íŒŒì¼ì„ ì°¾ìŒ

    # íŒŒì¼ëª…ì€ '0001_top_20250618_t0.jpg_detect.csv' í˜•ì‹ì´ë¯€ë¡œ,
    # base_nameì¸ '0001_top'ì´ ì ‘ë‘ì‚¬ê°€ ë¨.

    if is_t0:
        suffix_filter = '_t0.'
    else:
        suffix_filter = '_t1.'

    for filename in os.listdir(detect_csv_folder):
        # filenameì´ '0001_top'ìœ¼ë¡œ ì‹œì‘í•˜ê³ , '_t0.' ë˜ëŠ” '_t1.'ì„ í¬í•¨í•˜ë©°, '_detect.csv'ë¡œ ëë‚˜ëŠ”ì§€ í™•ì¸
        if filename.startswith(base_name) and filename.endswith('_detect.csv') and suffix_filter in filename:
            return filename

    return ""


# -------------------- ë§¤ì¹­ ë©”ì¸ --------------------
vehicle_global_id = 1
all_vehicle_records = []
t0_to_t1_map = defaultdict(list)
unique_t0_files = set()

# 1. t0t1_augmented.csv íŒŒì¼ì„ ì½ì–´ì™€ ë§¤í•‘ ìƒì„± ë° íŒŒì¼ëª… ì™„ì„±
if not os.path.exists(PAIR_CSV_PATH):
    print(f"[ì˜¤ë¥˜] í˜ì–´ íŒŒì¼ ì—†ìŒ: {PAIR_CSV_PATH}")
    sys.exit(1)

found_pair_count = 0
try:
    with open(PAIR_CSV_PATH, "r", newline="") as f:
        reader = csv.DictReader(f)
        if "t0_filename" not in reader.fieldnames or "t1_filename" not in reader.fieldnames:
            print("[ì˜¤ë¥˜] t0t1_pair.csvì— 't0_filename' ë˜ëŠ” 't1_filename' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            sys.exit(1)

        for row in reader:
            t0_base_name = row["t0_filename"].strip()
            t1_base_name = row["t1_filename"].strip()

            # ğŸš¨ ìˆ˜ì •ëœ complete_filename í•¨ìˆ˜ ì‚¬ìš©
            t0_filename = complete_filename(t0_base_name, detect_csv_folder, is_t0=True)
            t1_filename = complete_filename(t1_base_name, detect_csv_folder, is_t0=False)

            if t0_filename and t1_filename:
                t0_to_t1_map[t0_filename].append(t1_filename)
                unique_t0_files.add(t0_filename)
                found_pair_count += 1
            # else:
            #     print(f"[ê²½ê³ ] ë§¤ì¹­ë˜ëŠ” ì‹¤ì œ íŒŒì¼ëª…ì„ ì°¾ì§€ ëª»í•¨: T0={t0_base_name}, T1={t1_base_name}")

except Exception as e:
    print(f"[ì˜¤ë¥˜] t0t1_augmented.csv íŒŒì¼ì„ ì½ëŠ” ì¤‘ ë¬¸ì œ ë°œìƒ: {e}")
    sys.exit(1)

if found_pair_count == 0:
    print(f"[ì˜¤ë¥˜] t0t1_augmented.csvì—ì„œ ìœ íš¨í•œ íŒŒì¼ìŒì„ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. detect_csv í´ë”ì™€ íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”. íŒŒì¼ëª… í˜•ì‹ ë¬¸ì œì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.")
    # sys.exit(1) # ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì¶œë ¥í•˜ê³  ê³„ì† ì§„í–‰ (0% ë§¤ì¹­ë¥  ì˜ˆìƒ)

# 2. T0 íŒŒì¼ ìˆœíšŒ ë° T1 ë§¤ì¹­
total_t1_count = 0
matched_t1_count = 0

for t0_file in sorted(list(unique_t0_files)):

    t0_bboxes = read_detect_csv(t0_file)
    t0_feats = load_features(t0_file)

    if len(t0_bboxes) == 0:
        continue

    # T0 ë°•ìŠ¤ ID í• ë‹¹ ë¦¬ìŠ¤íŠ¸ (ID ì¤‘ë³µ í•´ê²°)
    t0_to_global_id = [-1] * len(t0_bboxes)

    # T0 ë°•ìŠ¤ í• ë‹¹ ì¶”ì  Set (T0 ë°•ìŠ¤ê°€ ì—¬ëŸ¬ T1 íŒŒì¼ì— ì¤‘ë³µ ë§¤ì¹­ë˜ëŠ” ê²ƒì„ ë°©ì§€)
    t0_assigned_in_t0_file = set()

    # T0ì— ì—°ê²°ëœ ëª¨ë“  T1 íŒŒì¼ ìˆœíšŒ
    for t1_file in t0_to_t1_map[t0_file]:

        t1_bboxes = read_detect_csv(t1_file)
        t1_feats = load_features(t1_file)

        if len(t1_bboxes) == 0:
            continue

        total_t1_count += len(t1_bboxes)

        t1_assigned = set()
        matched_pairs_t1 = []

        # -------------------- ë§¤ì¹­ ë¡œì§ --------------------

        # 1) í›„ë³´ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± & Hungarian ë§¤ì¹­
        # T0 ë°•ìŠ¤ê°€ ì´ë¯¸ ë§¤ì¹­ë˜ì—ˆë‹¤ë©´ cost matrix í›„ë³´ì—ì„œ ì œì™¸ (1e6)
        cost_matrix = np.full((len(t0_bboxes), len(t1_bboxes)), 1e6, dtype=float)
        metrics = {}

        for i, b0 in enumerate(t0_bboxes):
            if i in t0_assigned_in_t0_file:
                continue  # ì´ë¯¸ ë§¤ì¹­ëœ T0 ë°•ìŠ¤ëŠ” ì´ë²ˆ T1ê³¼ì˜ ë§¤ì¹­ í›„ë³´ì—ì„œ ì œì™¸

            candidate_list = []
            for j, b1 in enumerate(t1_bboxes):
                if min(b1[2] - b1[0], b1[3] - b1[1]) < MIN_BBOX_SIZE: continue
                iou = compute_iou(b0, b1)
                center_dist = center_distance(b0, b1)
                if iou < IOU_THRESH and center_dist > CENTER_RATIO * ((b0[2] - b0[0] + b0[3] - b0[1]) / 2.0): continue

                f0 = t0_feats[i].get("feature") if (i < len(t0_feats) and isinstance(t0_feats[i], dict)) else (
                    t0_feats[i] if i < len(t0_feats) and not isinstance(t0_feats[i], dict) else None)
                f1 = t1_feats[j].get("feature") if (j < len(t1_feats) and isinstance(t1_feats[j], dict)) else (
                    t1_feats[j] if j < len(t1_feats) and not isinstance(t1_feats[j], dict) else None)
                cos_sim = cosine_similarity(f0, f1)

                score = ALPHA * iou + BETA * cos_sim
                candidate_list.append((j, score,
                                       {"iou": iou, "center_dist": center_dist, "size_sim": size_similarity(b0, b1),
                                        "reid": cos_sim}))

            if candidate_list:
                candidate_list.sort(key=lambda x: x[1], reverse=True)
                for (j, score, metric) in candidate_list[:TOP_N_REID]:
                    cost_matrix[i, j] = 1.0 - score
                    metrics[(i, j)] = metric

        # 2) Hungarian 1:1 ë§¤ì¹­ ì‹œë„
        try:
            row_ind, col_ind = linear_sum_assignment(cost_matrix)
        except Exception:
            row_ind, col_ind = np.array([], dtype=int), np.array([], dtype=int)

        for r, c in zip(row_ind, col_ind):
            if r in t0_assigned_in_t0_file or c in t1_assigned or cost_matrix[r, c] >= 1e6: continue

            m = metrics.get((r, c), None)
            if m is None: continue
            final_score = ALPHA * m["iou"] + BETA * m["reid"]
            if final_score < FINAL_SCORE_THRESH: continue

            # **ID í• ë‹¹/ì¬ì‚¬ìš© ë¡œì§**
            current_id = t0_to_global_id[r]
            if current_id == -1:
                current_id = vehicle_global_id
                t0_to_global_id[r] = current_id
                vehicle_global_id += 1

            rec = {
                "vehicle_id": current_id,
                "t0_image": t0_file, "t1_image": t1_file,
                "t0_bbox": t0_bboxes[r], "t1_bbox": t1_bboxes[c],
                "iou": m["iou"], "center_dist": m["center_dist"], "size_sim": m["size_sim"],
                "reid_similarity": m["reid"], "final_score": final_score, "note": "hungarian"
            }
            t1_assigned.add(c)
            t0_assigned_in_t0_file.add(r)  # T0 ë°•ìŠ¤ ì‚¬ìš© ì™„ë£Œ ì²˜ë¦¬
            matched_pairs_t1.append(rec)
            matched_t1_count += 1

        # 3) ReID ë³´ì¡° (ê±°ë¦¬ ë¬´ì‹œ, ë†’ì€ ReID ê¸°ì¤€)
        for j, b1 in enumerate(t1_bboxes):
            if j in t1_assigned: continue
            best_idx, best_cos = -1, 0.0
            for i, b0 in enumerate(t0_bboxes):
                if i in t0_assigned_in_t0_file: continue  # ì´ë¯¸ ë§¤ì¹­ëœ T0 ë°•ìŠ¤ ì œì™¸

                f0 = t0_feats[i].get("feature") if (i < len(t0_feats) and isinstance(t0_feats[i], dict)) else (
                    t0_feats[i] if i < len(t0_feats) and not isinstance(t0_feats[i], dict) else None)
                f1 = t1_feats[j].get("feature") if (j < len(t1_feats) and isinstance(t1_feats[j], dict)) else (
                    t1_feats[j] if j < len(t1_feats) and not isinstance(t1_feats[j], dict) else None)
                cos_sim = cosine_similarity(f0, f1)

                if cos_sim >= REID_COSINE_THRESH and cos_sim > best_cos:
                    best_cos = cos_sim
                    best_idx = i

            if best_idx >= 0:
                m_iou = compute_iou(t0_bboxes[best_idx], b1)

                # **ID í• ë‹¹/ì¬ì‚¬ìš© ë¡œì§**
                current_id = t0_to_global_id[best_idx]
                if current_id == -1:
                    current_id = vehicle_global_id
                    t0_to_global_id[best_idx] = current_id
                    vehicle_global_id += 1

                rec = {
                    "vehicle_id": current_id,
                    "t0_image": t0_file, "t1_image": t1_file, "t0_bbox": t0_bboxes[best_idx], "t1_bbox": b1,
                    "iou": m_iou, "center_dist": center_distance(t0_bboxes[best_idx], b1),
                    "size_sim": size_similarity(t0_bboxes[best_idx], b1),
                    "reid_similarity": best_cos, "final_score": ALPHA * m_iou + BETA * best_cos, "note": "reid_assist"
                }
                t1_assigned.add(j)
                t0_assigned_in_t0_file.add(best_idx)  # T0 ë°•ìŠ¤ ì‚¬ìš© ì™„ë£Œ ì²˜ë¦¬
                matched_pairs_t1.append(rec)
                matched_t1_count += 1

        # Fallback A: ê°€ì¥ ê°€ê¹Œìš´ ë°•ìŠ¤ (ê±°ë¦¬ NEAREST_PIXELS ì´ë‚´)
        for j, b1 in enumerate(t1_bboxes):
            if j in t1_assigned: continue
            best_idx, best_dist = -1, float('inf')
            for i, b0 in enumerate(t0_bboxes):
                if i in t0_assigned_in_t0_file: continue  # ì´ë¯¸ ë§¤ì¹­ëœ T0 ë°•ìŠ¤ ì œì™¸

                dist = center_distance(b0, b1)
                if dist < best_dist:
                    best_idx, best_dist = i, dist

            if best_idx >= 0 and best_dist <= NEAREST_PIXELS:
                m_iou = compute_iou(t0_bboxes[best_idx], b1)

                # **ID í• ë‹¹/ì¬ì‚¬ìš© ë¡œì§**
                current_id = t0_to_global_id[best_idx]
                if current_id == -1:
                    current_id = vehicle_global_id
                    t0_to_global_id[best_idx] = current_id
                    vehicle_global_id += 1

                rec = {
                    "vehicle_id": current_id,
                    "t0_image": t0_file, "t1_image": t1_file, "t0_bbox": t0_bboxes[best_idx], "t1_bbox": b1,
                    "iou": m_iou, "center_dist": best_dist, "size_sim": size_similarity(t0_bboxes[best_idx], b1),
                    "reid_similarity": 0.0, "final_score": 0.0, "note": "fallback_nearest"
                }
                t1_assigned.add(j)
                t0_assigned_in_t0_file.add(best_idx)  # T0 ë°•ìŠ¤ ì‚¬ìš© ì™„ë£Œ ì²˜ë¦¬
                matched_pairs_t1.append(rec)
                matched_t1_count += 1

        # 6) ì•„ì§ ë§¤ì¹­ ì•ˆ ëœ t1ì€ ìƒˆ vehicleë¡œ ì²˜ë¦¬
        for j, b1 in enumerate(t1_bboxes):
            if j not in t1_assigned:
                rec = {
                    "vehicle_id": vehicle_global_id, "t0_image": "", "t1_image": t1_file,
                    "t0_bbox": [], "t1_bbox": b1, "iou": 0.0, "center_dist": 0.0, "size_sim": 0.0,
                    "reid_similarity": 0.0, "final_score": 0.0, "note": "new"
                }
                matched_pairs_t1.append(rec)
                vehicle_global_id += 1

        all_vehicle_records.extend(matched_pairs_t1)

# -------------------- CSV ì €ì¥ --------------------
single_csv_path = os.path.join(match_csv_folder, "all_matching_vehicles_refined_final.csv")
with open(single_csv_path, "w", newline="") as f:
    writer = csv.writer(f)
    writer.writerow([
        "vehicle_id", "t0_image", "t1_image",
        "t0_x1", "t0_y1", "t0_x2", "t0_y2",
        "t1_x1", "t1_y1", "t1_x2", "t1_y2",
        "iou", "reid_similarity", "final_score", "note"
    ])
    for rec in all_vehicle_records:
        t0_bbox = rec["t0_bbox"] if rec["t0_bbox"] else ["", "", "", ""]
        t1_bbox = rec["t1_bbox"] if rec["t1_bbox"] else ["", "", "", ""]
        writer.writerow([
                            rec["vehicle_id"], rec["t0_image"], rec["t1_image"]
                        ] + t0_bbox + t1_bbox + [
                            rec.get("iou", 0.0), rec.get("reid_similarity", 0.0), rec.get("final_score", 0.0),
                            rec.get("note", "")
                        ])

# -------------------- ê²°ê³¼ ìš”ì•½ ì¶œë ¥ --------------------
match_rate = (matched_t1_count / total_t1_count * 100.0) if total_t1_count > 0 else 0.0
print(f"[ì™„ë£Œ] CSV ì €ì¥: {single_csv_path}")
print(f"ì´ t1 ë°•ìŠ¤ ìˆ˜: {total_t1_count}, ë§¤ì¹­ëœ t1 ìˆ˜(ì‹ ë¢°ê¸°ì¤€ í†µê³¼ í¬í•¨): {matched_t1_count}, ë§¤ì¹­ë¥ : {match_rate:.2f}%")

subprocess.run([sys.executable, "matching visualization.py"])